# **Лабораторная работа**

## *Создание нейронной сети для распознавания рукописных цифр*



## Введение

В данном документе будут рассмотрены два варианта задания нейронных сетей (НС), а именно с использованием сверточной сети и без нее. Важно отметить, что нет какого-то единственного варианта задания НС, так как выбор определенной методики написания программы остается за программистом и основывается на множестве факторов. В параграфе «Подготовка» будут рассмотрены использованные средства и их установка, а в параграфе «Теория» объяснены ключевые моменты проекта и цели применения НС в целом.

### Теория

Сверточная нейронная сеть изначально планировалась как сеть для работы с изображениями. Обычные нейронные сети плохо подходят для больших изображений, так как, например, у нашего варианта входное изображение имеет размер 28х28 пикселей и при этом мы его представляем в градациях серого (от 0 до 255, где 0 соответствует черному, 255 - белому, а остальные цвета, это полутона, или градации серого). В итоге разложения получаем 28х28 пикселей в представлении значений цветов 0-255, а именно 784 значения. Из-за этого количество весов коэффициентов для первого слоя у нас 128*784, где 128 -количество нейронов первого слоя. Получается 10 035 весов коэффициентов, что, казалось бы, много для человека, но не для машины. Но что делать, если мы берем картинку, например 1920х1080? Тут уже нужно больше самих нейронов, при этом количество входных значений будет 2 073 600, а количество весовых значений для нейронов первого слоя (предположив тут 1000 нейронов) будет равно немногим более 2 млрд. (если представлять в градациях серого, а в цветных изображениях это значение будет еще в три раза больше). При таких изображениях начинаются проблемы с оптимизацией процесса и сеть будет неэффективна. Поэтому для решения этой проблемы была придумана сверточная нейросеть. Простым языком, она берет значения пикселей 3х3 (то есть 9 пикселей) и прогоняет его через первый слой (где происходит выделение и распознавание простейших геометрических объектов, например вертикальных прямых). Такими квадратами, со сдвигом на один пиксель, она пройдет все изображение (см. рис. 1).

![img](https://lh7-us.googleusercontent.com/BtFimWRqztc1BO13hIbiUrtkdcVZMBVccNUoBexvQUjvhsTL_Iz7sEnXosCEJE6fDCo1qncmWBMAPXOglP8Ob-Q8oEpkNkvGFKBS8Os_4NX89c8uY5q5GVgZ_U8chK7Fk5BMamsTbfVbc2kkbcPJ_g)

*Рисунок 1. Пример прохода, квадратом 3х3, по изображению.*

Здесь получается намного меньше весов т.к. для всего изображения используется одно значение в каждом проходе (например, сначала проходит по всему изображению и определяет простейшие прямые и для каждой прямой разное значение). Потом то же самое, например, для горизонтальных линий, а дальше сможет распознавать более сложные геометрические объекты и так далее до полноценного изображения (рис. 2).

![img](https://lh7-us.googleusercontent.com/HwtfPFSEgqMai6Y-BWxJrAfeHbk1fojwIy6LIspoUANOrF7xA-5Ket-MLABoIX3Z0YZqM-oxCFwKqhdNo14ivxT_dHnNin0O6M3ydjLn8nJ1htoNnQmJa_GPBHXhFFH8PtH22IiSgtdlyfZ9s0fRjQ)

*Рисунок 2. Упрощенный принцип действия сверточной сети.*

В нашем проекте задача простая, если рассматривать относительно распознавания лиц на фотографиях с большим разрешением, поэтому мы можем упростить структуру НС до полносвязной с тремя слоями (входные значения, скрытый слой нейронов, выходные значения). Ниже в коде будет представлена схема такой НС (см. Этап I, вторая модель).

### Об используемых библиотеках

TensorFlow и Keras - два популярных фреймворка для разработки нейронных сетей, которые часто используются вместе, но имеют свои особенности. 

![img](https://lh7-us.googleusercontent.com/xPeQAbQaNoNXHQNM3HPUr1mDnAvKkDO5sABkoyu2xvSwUUYaL3snjGViQDN-4tBmjsaMx07NcG2zvKDJwV9i5MbnBYqkSDU3Wh4tykVrc1ehiB8Gt4x_8mvUAEl3N_fLgqAQIbY_WwTc)

TensorFlow - это мощная библиотека машинного обучения с открытым исходным кодом от Google. Она предоставляет гибкие средства для построения и тренировки нейросетей любой архитектуры и сложности. В TensorFlow можно легко реализовывать современные архитектуры нейронных сетей, а также использовать предобученные модели как базу для дальнейшей настройки. Однако для эффективной работы с TensorFlow требуются глубокие знания машинного обучения и программирования.

Keras - это высокоуровневый API, который упрощает разработку нейросетей на базе TensorFlow или других библиотек. Он предоставляет простой и интуитивно понятный интерфейс для быстрой сборки и тренировки стандартных архитектур нейронных сетей. Keras не так гибок как TensorFlow, зато значительно проще в изучении для начинающих.

Для задач распознавания изображений, таких как классификация рукописных цифр, рекомендуется использовать TensorFlow. Он позволяет точно настроить архитектуру нейросети и гиперпараметры для достижения максимального качества. Возможность масштабирования на мощные GPU кластеры также дает преимущество TensorFlow при обучении больших нейросетей на объемных датасетах изображений.

## Подготовка

### Общее для моделей

Теперь необходимо зарегистрироваться в Google Colab. Эта платформа облачных вычислений позволяет создавать, редактировать, тестировать и эксплуатировать код на различных языках программирования, используя мощности серверов вместо своего ПК. Также этот сервис позволяет удобно разрабатывать программу вместе с другими людьми прямо в общей облачной папке.

Для начала необходимо войти на страницу [Google Colab](https://colab.research.google.com/) и, если требуется, пройти регистрацию/авторизацию через аккаунт Google. Далее нажимаем на кнопку Файл – Создать Блокнот (см. рис. 3). После этого мы попадаем на новую вкладку, после необходимо проверить наличие фала на Google Диск. Если файл не появился на диске, то необходимо зайти на него, нажать кнопку Новый файл – Больше и затем нажать на Google Colaboratory или найти ее в Больше приложений, если здесь она не появилась (см. рис. 4).

![img](https://lh7-us.googleusercontent.com/3_yoaeDl7S1xcx41tMpsEVXISgpoZEo7KiKfiNkNXArX6tvz2n4_9II_n9ixya-sZWyJvhL0SMZln3kLDnxwf60BEt4CiPLInHdHlyRrlqOVWaSnktL899lPqtVeBamKRCY-ZIqMilxD4tvMGmCmFw)

*Рисунок 3. Создание файла.*

![img](https://lh7-us.googleusercontent.com/4vrzBLpO226KHixwSi4yH_GqPVNGZckjF5gy8OhqomSbWodTwnXV4Diw56nSB_3SOBRM0taksrstsLtC8PHSGoO4134L_k1aywoaMJj75YN-ugFqqySUjqSJ05mOZY8qfFv5oi-BR8dKJhvHY0_HUg)

*Рисунок 4. Добавление Google Colab на диске.*

### Для первой модели:

Для первой модели нам потребуется Visual Studio Code. Для его установки заходим на [официальный сайт](https://code.visualstudio.com/) и скачиваем бесплатную версию. После установки открываем программу, заходим в раздел аддонов и устанавливаем аддон Live Server.

![img](https://lh7-us.googleusercontent.com/N063LLoM8X5Pg-WOSkGhXH_RzmUEYIy21PKSxJFV83gDsGGWkbsVhH3te65IRxsIGpBBzZSVS6lXvXSccouw9agkLx7WvT3kcr_tGQTSc8kCaaLvP3cljT03VX1BvJzpPLYRgcuw7mQQLhqK8uJ35w)

*Рисунок 5. Установка Live Server в Visual Studio Code*

### Для второй модели:

Начнём с установки Python 3. Через браузер, заходим на официальный сайт [Python](http://www.python.org/) и скачиваем установочный файл (рис. 6).

![img](https://lh7-us.googleusercontent.com/jBT-Psq72qK3FurTT4JODaCv1OS06viRDP4PQswPfmqS8CgXHlHaH5zJGpguuMvRPLdKD4RFpyAX5ew9cTpbMQXoq1L6F5pzvn_twoEvDfjeqmKyZaFvjlVtTdN0ugT3mJ0pVkWuEdi7A0IedJiwdQ)

*Рисунок 6. Официальный сайт python.org.*

Далее, устанавливаем скачанный файл на компьютер. Рекомендуется оставить параметры установки по умолчанию (рис. 7).

![img](https://lh7-us.googleusercontent.com/yy9ywIr3IiYL9ASuEDRU3K7Sn551m2CKfKRa5iceU0SOR_Wz1sx6DrEUBOTNPiUNRtuLpnlf3QCjh0mugMegqq7ULK_6Y4ZNiObRmEYWE22HzBoR_I_QsF26R40Z2t9kzX-bG6cVGX1qKczJS942wQ)

*Рисунок 7. Пример установки Python 3*

---

**Важно:** cледует поставить помеченную внизу галочку во избежание проблем с переменными сред в дальнейшем.

---

Далее установим IDE [PyCharm](https://www.jetbrains.com/pycharm/) для более удобного отображения, но это необязательно.

![img](https://lh7-us.googleusercontent.com/m_uS9qwJN1Z629I5ow9OAwLs-6zR_k5nvl_xe73I1rPrrPvAX-_Qph7LtKax5K5HUzr_mfdPIOU1BpUuLLReC-tII8w1jSe6BCYoAiYFun5PBb8kfW4uAOH81NWKeDU9fCL-hL76RvweukfFlghGdQ)

*Рисунок 8. Официальный сайт JetBrains и их продукт PyCharm.*

![img](https://lh7-us.googleusercontent.com/h2yqU7ZQv1HXPfjHYbUqP6U4IK_tpQhqfrhCHt9ITs-lXOGYdLzO3om6UADB3tGIYc8KrQgehpyWhKc4sAQfEU0VIIdLfpff0FB7HBW2ULaUNn0UgE7S70XipHB3w5VKcq_Nhj4W278olkV00LjunA)

*Рисунок 9. Скачивание бесплатной (не профессиональной) версии.*

Следуя указаниям установщика, устанавливаем PyCharm на компьютер. Теперь займёмся непосредственно установками библиотек в PyCharm.Для их установки открываем PyCharm, переходим во вкладку Terminal.

![img](https://lh7-us.googleusercontent.com/zhJATo7UnjWFBmTvpWaDaZxZL5XCi1s2cyqyBeMrwWO-qDzY1SievwmNIV_x8fQhPSgzO_-gsZHQsU3hOevD9Ww4Owvp8-tmARk_EoEtjJmvLaOTvQaRE1jfCExBUJN9Tq2AbEgUDmfHUTKRvoRmsg)

*Рисунок 10. Открытие терминала установки библиотек внутри PyCharm*

Внутри терминала устанавливаем необходимые библиотеки с помощью консольной команды pip install.

Для создания второй модели нам также потребуется библиотека `tensorflow`, `matplotlib`, однако, ко всему этому, нам нужно будет установить библиотеки `numpy`, `pillow`, `keras`, `pywin32`. Помимо этого будет использоваться библиотека `tkinter`, не требующая дополнительной установки. 

## Этапы создания нейронной сети

### Этап I. Создание простой модели распознавания цифр на наборе данных MNIST

### Первая модель:

Первым шагом при работе с моделями в Google Colab является настройка оптимальной среды выполнения с использованием GPU.

**Чтобы изменить тип среды выполнения в Google Colab с CPU на GPU:**

1. Откройте меню "Среда выполнения" в верхнем меню.

<img src="https://lh7-us.googleusercontent.com/QrVQ0k65ULBnOiqvirvn_CII5OnFYWzJJgXjuKsI67UUr3AjTmdHzotCstjBAwOJI5OA7oXuKXIXvdTWxgJ_-cNYjWoa7dk40Mqy06bVp-Nrv32bDFclspvelXfyj-KujrwoFnybUVmt" alt="img" style="zoom:33%;" />

2. Выберите "Сменить среду выполнения".

<img src="https://lh7-us.googleusercontent.com/0RM5hWW1XPLSp-_ilInkKwE9UpmEvGqzUeo_-6WNmLbinMfzUj69oaX7IV8ZXxsYjR91CptI7p5gcwvVoqpW1TCgjzDZ3WhmogusWIaebqtEoHisznK5Qj03wwTj8MhWqILIJCP9T0bS" alt="img" style="zoom:33%;" />

3. В открывшемся окне из выпадающего списка выберите "GPU" в качестве аппаратного ускорителя.

<img src="https://lh7-us.googleusercontent.com/DDLEOrf-y-VByDmv39WqkG-AnUDdNSV-E9P4cdx5aWrPoUxUWaWf88MoYpatGkiD1A82NmZKOIXm3cUYTl2KS5K1zX29e4HVrvalAW6RilBLPzmHUydgfFl5rUc1aZthn-BMxp-m90h0" alt="img" style="zoom:33%;" />

4. Нажмите Сохранить.

Использование GPU дает значительное ускорение обучения нейронных сетей и других моделей машинного обучения за счет параллельных вычислений на GPU, до 10-20 раз по сравнению с CPU в задачах глубокого обучения. Также появляется возможность обучать более сложные и глубокие нейронные сети за меньшее время, и эффективно масштабировать вычисления при увеличении размера данных и моделей.

1. **Разделим код внутри Google Colab на блоки, внутри каждого этапа. Внутри первого блока:**

```python
import tensorflow as tf

# импортирование набора данных цифр
mnist = tf.keras.datasets.mnist
(tx, ty), (vx, vy) = mnist.load_data()

# предварительная обработка входных типов
tx = tx[:,:,:,None].astype('float32')
vx = vx[:,:,:,None].astype('float32')
ty = ty.astype(int)
vy = vy.astype(int)

# отображение соответствующей информации
print("""tx:%s, ty:%s
vx:%s, vy:%s""" % (tx.shape, ty.shape, vx.shape, vy.shape))
```

Данный код отображает размерности данных tx и цели ty, а также данных валидации vx и целевых данных vy:

```python
tx:(60000, 28, 28, 1), ty:(60000,)
vx:(10000, 28, 28, 1), vy:(10000,)
```

2. **Выведем 10 образцов изображений каждой цифры, чтобы понять, как выглядят данные:**

   ```python
   import matplotlib.pyplot as plt
   
   # создаём сетку участков
   f, axs = plt.subplots(10,10,figsize=(10,10))
   
   # построим номер выборки в каждом подначертании
   for i in range(10):
     for j in range(10):
       # получить образец изображения для номера 'i'
       img = tx[ty==i,:,:,0][j,:,:]
   
       # построим изображение по осям
       axs[i,j].imshow(img, cmap='gray')
   
   
       # удалим оси x и y
       axs[i,j].axis('off')
   
   # удалим ненужные пробелы
   plt.tight_layout()
   
   # выведем изображение
   plt.show()
   ```

   Обратите внимание на чёрный фон и белые цифры. Это важно в смысле рисования чисел и кода canvas в HTML:

   ![img](https://lh7-us.googleusercontent.com/pxSH-pxe3-lk9PA1sTRDmxjyAOFTcMmahMVP9O-4P_DfTLojdhcZbAe1MN5-d0TPOzfhPw85ErLLESe4Et5OHcAZ_HNz_v8b74o-9cuz4YXFdQNvlopAjYiXkFAw2KH_fZ4wOyWK4tlNWLQfZGbLpg)

*Рисунок 11. Примеры цифр из обучающей выборки библиотеки MNIST.*

3. **Начнём со строительного блока свёртки, который кроме самой свёртки будет содержать пакетную нормализацию, функцию активации RELU, максимальное объединение и отсеивающие слои:**

   ```python
   def normConvBlock(filters, return_model=True, name=None):
     lays = [
       tf.keras.layers.Conv2D(filters, 3, padding='valid', name=name+'_conv'),
       tf.keras.layers.BatchNormalization(name=name+'_bn'),
       tf.keras.layers.Activation('relu', name=name+'_act'),
       tf.keras.layers.MaxPooling2D(2, strides=2, name=name+'_mpool'),
       tf.keras.layers.Dropout(0.1, name=name+'_drop'),
     ]
   
     if return_model:
       return tf.keras.models.Sequential(lays, name=name)
     else:
       return lays
   ```

4. **Наша полная сеть будет состоять из двух `normConvBlock`, затем плоского и последнего плотного слоя с активацией `softmax`. В целевых данных есть маркировка порядка, поэтому также воспользуемся категориальной потерей перекрёстной энтропии:**

   ```python
   # создаём модель
   model = tf.keras.models.Sequential()
   model.add(normConvBlock(64, name='b1'))
   model.add(normConvBlock(128, name='b2'))
   model.add(tf.keras.layers.Flatten(name='flat'))
   model.add(tf.keras.layers.Dense(10, activation='softmax', name='logit'))
   
   model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])
   
   # тестирование модели с образцом изображения
   _ = model(tx[:1,:,:,:])
   
   # краткое описание структуры модели
   tf.keras.utils.plot_model(
       model,
       show_shapes=True,
       show_layer_names=True,
       show_dtype=True,
       expand_nested=True,
       dpi = 50
   )
   ```

   Код выше отобразит структуру модели:

   ![img](https://lh7-us.googleusercontent.com/cmabQUWc6nroNg3OJivDSZIlZgTr_9m0QhSQU86VEpJ14IOU9M46o1uLBXSjhhHoLemDYQlNspErXtNHtdZ1-3eql1EXQcXxqZM3uw8PWVSSUv91I6voTv5ywRwVOca4VDRMkTO9U0R-ZiRnNMrosg)

*Рисунок 12. Структура модели.*

### Вторая модель:

При работе с небольшими нейронными сетями в Keras использование GPU не даст существенного преимущества в скорости по сравнению с CPU.

Это связано с тем, что при обучении небольших моделей большую часть времени занимают накладные расходы на инициализацию GPU и передачу данных между CPU и GPU.

1. **Здесь аналогично делим всё на блоки внутри Google Colab. В первом блоке импортируем и устанавливаем необходимые нам библиотеки:**

```python
!pip install tensorflowjs
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import mnist #библиотека базы выборок
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Sequential
from google.colab import files
%matplotlib inline
```

2. **Во втором блоке загружаем обучающую и тестовую выборку:**

```python
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

3. **Следующий блок отвечает за нормализацию входных данных:**

```python
x_train = x_train / 255
x_test = x_test / 255
```

4. **Затем преобразуем данные в векторы по категориям:**

```python
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)
```

5. **В данном блоке формируем модель НС и выводим в консоль:**

```python
model = Sequential([
    Flatten(input_shape = (28, 28, 1)),
    Dense(128, activation ='relu'),
    Dense(10, activation = 'softmax')
])


print(model.summary())
```

6. **Компилируем модель:**

```python
model.compile(optimizer = 'adam',
              loss = 'categorical_crossentropy',
              metrics=['accuracy'])
```



![img](https://lh7-us.googleusercontent.com/ntCJumrTy-RA76lyoDSHe4oZaaBv5iFIx_SeHi8r3seaGfUiUrrYTzZ-QDbsQliWOx0xfQAMYaTA3wvknG8Z4EVb38K85uAkBHuyEuhOF3DM9DYu3nLgihGaOJpAEuYglU6HemEa4FS2ebn8HoBhoQ)

*Рисунок 13. Данный рисунок визуально описывает строение данной НС.*

### Этап II. Обучение модели распознавания цифр на наборе данных MNIST

### Первая модель:

1. **Чтобы обучить модель, вызовем `model.fit` с обработанными выше данными, а также определим обратный вызов ранней остановки, чтобы избежать переобучения:**

```python
 #определим обратный вызов для ранней остановки. Этот обратный вызов загрузит итерацию с наилучшим показателем val loss в конце тренировки
#es_call = tf.keras.callbacks.EarlyStopping(
    #monitor='val_loss', min_delta=0, patience=2, verbose=0,
    #mode='auto', baseline=None, restore_best_weights=True
#)

# подгонка модели под набор данных mnist
history = model.fit(tx, ty, validation_data=(vx, vy), epochs=25, batch_size=1024) #callbacks=[es_call])
```

---

**Важно:** Закомментированная часть кода определяет callback функцию ранней остановки обучения Keras (EarlyStopping). Она используется для того, чтобы остановить обучение модели, если метрика валидации перестала улучшаться. Так как эта часть закомментирована, callback ранней остановки не будет использоваться в модели. Функция EarlyStopping закомментирована, чтобы при тестировании модели задавать конкретное число эпох (epochs=25). Это нужно чтобы результаты тестирования были воспроизводимыми при фиксированном числе эпох обучения.

---

### Вторая модель:

**Запуск процесса обучения НС:**

```python
model. fit(x_train,y_train_cat, batch_size=100, epochs=10, validation_split=0.2)
```

![img](https://lh7-us.googleusercontent.com/P4GmCnHKptVMBoL-mv8FKYaHEiQgsPFHKQPy2EXd4zYT9M4xD4IDVC2wU0IEQF12-gtDNMw17Hu5u0XHk8ama_jhF3-H8FV7P12OqQE4917OaMjJSjG7c21XSQYyttupw-G3CwFeS4MEi8215mr--Q)

*Рисунок 14. Процесс обучения модели*

Важно знать, что все это значит:

- **Xms/step**: время, затрачиваемое на один шаг
- **loss**: критерий качества (чем меньше – тем лучше)
- **accuracy**: точность определения (1 = 100%, чем больше – тем лучше)
- **val_loss** и **val_accuracy**: критерии валидации

Критерии к обучению модели будут указаны в части вывода.

**Проверка и сохранение модели:**

После процесса обучения пореверяем на первом элементе тестовой выборки. (можно этого не делать, это так сказать для спокойствия, что все верно)

```python
n=0
x=np.expand_dims (x_test[n],axis=0)
res=model.predict (x)
print(res)
print(f"распознання цифра: {np.argmax(res)}")
```

```
1/1 [==============================] - 0s 346ms/step
[[1.6363211e-08 5.1235372e-10 5.4209846e-07 3.3271749e-04 1.5196847e-11
  5.5687233e-10 1.9919577e-14 9.9966633e-01 1.2094674e-07 2.3813431e-07]]
распознання цифра: 7
```

### Этап III. Скачивание натренированной модели

### Первая модель:

1. **После того, как завершится тренировка нашей модели, нам необходимо её сохранить. Преобразуем `TensorFlow` в `TensorFlow.js`. Для этого можно вызвать метод `tensorflowjs.converters.save_keras_model` библиотеки `tensorflowjs`**.

```python
!pip install tensorflowjs > /dev/null 2>&1 #Это нужно выполнить только один раз для установки зависимостей. В дальнейшем, после установки, эту строку можно закомментировать для экономии времени
import tensorflowjs
print(tensorflowjs.__version__)


# конвертируем модель keras в tensorflow js
tensorflowjs.converters.save_keras_model(model,'./mnist_tf_keras_js_model/')
```

2. **После этого можно скачать нашу модель:**

```python
# загрузим сгенерированные файлы из colab на компьютер
from google.colab import files

files.download("mnist_tf_keras_js_model/group1-shard1of1.bin")
files.download("mnist_tf_keras_js_model/model.json")
```

### Вторая модель:

1. **После окончания обучения необходимо сохранить нашу модель, для этого используем:**

```python
model.save('16_model.h5')
```

2. **После скачиваем нашу модель:**

```python
from google.colab import files
files. download("16_model.h5")
```

### Этап IV. Написание интерфейса

### Первая моделть:

1. **Начнём с создания основного каталога, который будет хранить наши файлы.**

Создадим папку `digit_recognition` в любом удобном для нас месте. После этого необходимо создать внутри папки `digit_recognition` папку `tensorflow`. Ко всему этому, используя любой текстовый редактор, например Блокнот, создаем в папке `digit_recognition` файл `index.html` и `script.js`

После этого копируем ранее скачанные файлы модели в папку `tensorflow`, которую мы создали в предыдущем шаге. В результате получаем такую файловую систему:

![img](https://lh7-us.googleusercontent.com/2vWqv2fpZmZHH3M2giGpnv64FrXahcpjEMp0Uhxw4AstFAAZNUS_nwuE2a_jn_3KwaElDZIi0K_0rCdjNb1FuRyZghaaq7YcRatMbEniCV7Sjqsq9fHXUvuYfD9WiJr6V5kynUJepkyN)

*Рисунок 15. Полученная файловая система*

2. **С помощью того же блокнота открываем файл `index.html` и помещаем туда код:**

```html
<html>
  
  <head>
    
    <!-- Импортируем TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0"> </script>

    <!-- Импортируем tfjs-vis -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.5.1/dist/tfjs-vis.umd.min.js"></script>
    
  </head>
  
  <body>
    
    <!-- Определяет контейнер с кнопками предсказания и стирания, а также холст для рисования цифры -->
    <div id="container">
      
      <h1>Draw a number</h1>
      <p id="result">Prediction </p>
      
      <div>
        <!-- Эта кнопка даёт команду модели вернуть ответ для текущего рисунка на холсте -->
        <button type="button" class="btn btn-primary btn-block" onclick="predictModel()">Predict</button>
        
        <!-- Эта кнопка очищает холст, чтобы мы могли нарисовать новую цифру -->
        <button type="button" class="btn btn-secondary btn-block" onclick="erase()">Clear</button>
      </div>
      
      <!-- Это определяет холст, на котором мы можем нарисовать цифру. 
           Также здесь мы можем регулировать размер холста -->
      <canvas id="canvas" width="386px" height="386px" class="canvas" style="border:1px solid #b9bfc9;margin-top:25px;"></canvas>
    </div>

    <!-- Импортируем основной файл сценария -->
    <script src="script.js"></script>
    
  </body>
  
</html>

```

Разберём код:

- В разделе `<head>` загружаются TensorFlow.js и её зависимости.
- Строка 23 создаёт кнопку вызова функции вывода модели **predictModel**, которая запустится после нажатия, результат предсказания вы увидите в теге `<p id="result">`.
- На строке 26 создаётся кнопка очистки холста **erase**.
- Строка 31 определяет объект **canvas**, где мы будем рисовать цифру для распознавания.
- В строке 35 содержится файл `script.js` с логикой JavaScript, которая переносит цифру с холста в тензор и применяет модель.

3. **Откроем файл `script.js` и добавим показанные ниже фрагменты кода:**

   1. Основные переменные скрипта:

   ```js
   // определяет соответствующие переменные
   var canvas = document.getElementById("canvas");
   var ctx = canvas.getContext('2d');
   var dragging = false;
   var pos = { x: 0, y: 0 };
   ```

   2. Триггеры:
      - По событию **mousedown** (нажатию и удержанию кнопки) запускается сценарий, который инициирует рисование и записывает текущее положение мыши/прикосновения.
      - По событию **mousemove** скрипт начинает рисовать на холсте. По **mouseup** (когда отпускаем кнопки мыши) срабатывает останавливающий рисование скрипт:

   ```js
   // определим слушателей событий для ПК и телефонов
   
   // Движение мышкой
   canvas.addEventListener('mousedown',  engage);
   canvas.addEventListener('mousedown',  setPosition);
   canvas.addEventListener('mousemove',  draw);
   canvas.addEventListener('mouseup', disengage);
   
   // Касание
   canvas.addEventListener('touchstart', engage);
   canvas.addEventListener('touchmove', setPosition);
   canvas.addEventListener('touchmove', draw);
   canvas.addEventListener('touchend', disengage);
   ```

   3. Чтобы правильно выбрать событие в **setPosition**, напишем функцию проверки того, поддерживается ли устройством сенсорное управление:

   ```js
   // определим, является ли устройство сенсорным
   function isTouchDevice() {
     return (
       ('ontouchstart' in window) ||
       (navigator.maxTouchPoints > 0) ||
       (navigator.msMaxTouchPoints > 0)
     );
   }
   ```

   4. Определим флаги начала и прекращения рисования:

   ```js
   // определим базовые функции для обнаружения нажатия и отпускания
   
   function engage() {
     dragging = true;
   };
   
   function disengage() {
     dragging = false;
   };
   ```

   5. Запишем положение мыши/прикосновения. Обратите внимание, что нам нужно знать, поддерживается ли сенсорное управление:

   ```js
   // получим новую позиции при событиях связанных с мышью или прикосновением к экрану
   function setPosition(e) {
   
     if (isTouchDevice()) {
     	var touch = e.touches[0];
     	pos.x = touch.clientX - ctx.canvas.offsetLeft;
     	pos.y = touch.clientY - ctx.canvas.offsetTop;
     } else {
     
   	  pos.x = e.clientX - ctx.canvas.offsetLeft;
     	pos.y = e.clientY - ctx.canvas.offsetTop;
     }
   }
   ```

   6. Перейдём к функции рисования. Флаг **draging** определяет, рисует ли пользователь прямо сейчас. Если это так, между прошлой позицией из **setPosition** и текущей позицией возникает линия:

   ```js
   // рисуем линию на холсте при нажатой кнопке мыши
   function draw(e) {
     
     e.preventDefault();
     e.stopPropagation();
   
     // для рисования необходимо, чтобы пользователь был активен (dragging = True)
     if (dragging) {
   
       // начало рисования
       ctx.beginPath();
     
       // параметры линии
       ctx.lineWidth = 40;
       ctx.lineCap = 'round';
       ctx.strokeStyle = 'red';
   
       // получаем текущую позицию, переместимся в новую, создавая линию от текущей до новой
       ctx.moveTo(pos.x, pos.y);
       setPosition(e);
       ctx.lineTo(pos.x, pos.y);
   
       // рисуем
       ctx.stroke();
     }
   }
   
   
   // очищаем холст
   function erase() {
     ctx.clearRect(0, 0, canvas.width, canvas.height);
   }
   ```

   7. Загрузим модель. Метод **tf.loadLayersModel** загружает модель по URL или из локального каталога. При первом предсказании она инициализирует веса, поэтому, чтобы во время первого предсказания избежать задержки, рекомендуется «разогреть» её:

   ```js
   // определяет функцию загрузки модели TF
   async function loadModel(){	
     	
     // загружаем модель
     model = await tf.loadLayersModel('tensorflow/model.json');    
     
     // теплый старт модели. ускоряет первый вывод
     model.predict(tf.zeros([1, 28, 28, 1]))
     
     // возвращаем модель
     return model
   }
   ```

   8. Получим текущие данные о цифре с холста:

   ```js
   // получаем тензор изображений с холста
   function getData(){
     return ctx.getImageData(0, 0, canvas.width, canvas.height);
   }
   ```

   9. Функция выводов модели:
      - **getData** загружает данные холста.
      - **tf.browser.fromPixels** преобразует их в тензор.
      - **tf.image.resizeBilinear** изменяет размер изображения до размера для модели.
      - **model.predict** получает предсказание, **getElement** устанавливает цифру из прогноза **y.argMax(1)** в тег `<p id="result">`.

   ```js
   // определяем функцию вывода модели
   async function predictModel(){
       
     // получаем данные изображения
     imageData = getData();
     
     // преобразуем объект данных canvas в тензор
     image = tf.browser.fromPixels(imageData)
     
     // предварительная обработка изображения
     image = tf.image.resizeBilinear(image, [28,28]).sum(2).expandDims(0).expandDims(-1)
     
     // получаем предсказание модели
     y = model.predict(image);
     
     // заменяем текст в теге result на предсказание модели
     document.getElementById('result').innerHTML = "Prediction: " + y.argMax(1).dataSync();
   }
   
   // загрузка модели
   var model = loadModel()
   ```

### Вторая модель:

Для создания интерфейса воспользуемся PyCharm, создаем новый файл с расширением .py и названием gui.

1. **Начнём, как и всегда, с подключения всех необходимых библиотек:**

```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from keras.models import load_model
from tkinter import *
import tkinter as tk
import win32gui
from PIL import ImageGrab, Image,ImageOps
import numpy as np
import matplotlib.pyplot as plt
```

2. **Далее загружаем нашу модель из файла:**

```python
model = load_model('16_model.h5')
```

3. **После этого приступаем к написанию функции преобразования и обработки изображения:**

```python
def predict_digit(img):
    # изменение рзмера изобржений на 28x28
    img = img.resize((28, 28))
    # используем библиотеку opencv для инверсирования цветов
    img = ImageOps.invert(img)
    # конвертируем rgb в grayscale
    img = img.convert('L')
    img = np.array(img)

    # изменение размерности для поддержки модели ввода и нормализации
    img1 = img.reshape(-1, 28, 28, 1)

    img1 = img1 / 255

    # предсказание цифры

    res = model.predict(img1)
    print(res)
    res = list(res)
    print(res)
    return np.argmax(res)
```

4. **Теперь, используя библиотеку TKinter, мы создаем графический интерфейс:**

```python
class App(tk.Tk):
    def __init__(self):
        tk.Tk.__init__(self)

        self.x = self.y = 0

        # Создание элементов
        self.canvas = tk.Canvas(self, width=300, height=300, bg="white", cursor="cross")
        self.label = tk.Label(self, text="Думаю..", font=("Helvetica", 48))
        self.classify_btn = tk.Button(self, text="Распознать", command=self.classify_handwriting)
        self.button_clear = tk.Button(self, text="Очистить", command=self.clear_all)

        # Сетка окна
        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )
        self.label.grid(row=0, column=1, pady=2, padx=2)
        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)
        self.button_clear.grid(row=1, column=0, pady=2)

        self.canvas.bind("<B1-Motion>", self.draw_lines)

    def clear_all(self):
        self.canvas.delete("all")

    def classify_handwriting(self):
        HWND = self.canvas.winfo_id()
        rect = win32gui.GetWindowRect(HWND)  # получаем координату холста
        im = ImageGrab.grab(rect)
        digit = predict_digit(im)
        self.label.configure(text=str(digit))

    def draw_lines(self, event):
        self.x = event.x
        self.y = event.y
        r = 8
        self.canvas.create_oval(self.x - r, self.y - r, self.x + r, self.y + r, fill='black')


app = App()
mainloop()
```

### Этап V. Написание интерфейса

### Первая модель:

Ради безопасности браузеры ограничивают HTTP-запросы от скриптов. Это означает, что веб-приложение может запрашивать ресурсы только из того источника, откуда оно загрузилось, если ответ от других источников не содержит правильных заголовков Cross-Origin Resource Sharing (CORS). Обойдём это с помощью Visual Studio Code. 

Запускаем Visual Studio Code, после открываем нашу папку digital_recognition: File - Open folder. После этого выделяем наш `index.html`, нажимаем правой кнопкой мыши и выбираем Open with Live Server. 

<img src="https://lh7-us.googleusercontent.com/qrWmglRW71lcR1kyRSrW0-N_36hBSYeP21bXbFYHQWL1uY4Ds1O9j6l12Ut1dfkv4Wxues-OYV2Q5z9uX1TIv4Rfq5oxamyWj7fvzzTDTOKzf8rU8fwW0rLZ4pRBiVdLxbIH8S05tAIa65idfH8Cyg" alt="img" style="zoom:67%;" />

*Рисунок 16. Запуск Live Server*

После этого у нас откроется локальный сайт с нашей моделью. Теперь она полностью функционирует, мы можем писать числа и после нажатия на Predict получать результат.

<img src="https://lh7-us.googleusercontent.com/4qUSGZhZIzrd1BzcBSvJUHTrlYIIBG9sZcf-E6dcGx1QFg-bCYEM_a8OYdYn94ZyuXNbBc49P2Ug0Ka3ysVHUDiAPD9zwG7QbmAJqZ7DNKm8P7DlDkq16uUFSbJeDln_ywwePISYM4ZQ" alt="img" style="zoom: 15%;" />

*Рисунок 17. Пример распознанной цифры*

### Вторая модель:

Для тестирования модели просто компилируем код файла `gui.py`, после чего получаем интерфейс:

![img](https://lh7-us.googleusercontent.com/ME-BhXVmxeNVbOqOEg3a3zPXOBVlv1ua8nTU-CbhVj26cpByDa20aI8oGtlbWpAWZyYErisEBajhmsbYrZe8EtmSqdc0hHguOHr4n9X52Zj0vMPtVbkb6OuA8zpznJY_12FWiJsLvQfOVje_pX5R6Q)

*Рисунок 18. Интерфейс второй модели*

После этого можно проверить работоспособность.

![img](https://lh7-us.googleusercontent.com/sV2yOqemmzF6URiasg9lFbIbyERJkEZpBJdig-lENUUoaZQGAl0p1Z7kkXmqO0Kzb-v4mwjX4J_Qd4rwr8rbmhcjl3HS4xkshFEZwUwakqFPr_ryK4rXJfpEH8ca0PqyPesoE0Scab3S)

*Рисунок 19. Распознанная цифра с помощью второй модели*

---

**Важно:** Стоит отметить, что точность первой модели выше, чем точность второй.

----

## Выводы

Во время разработки этого проекта было выяснено практическими методами, что написание заданной программы вполне возможно как через сверточную, так и полносвязную нейронную сеть, несмотря на то что сверточная сеть выигрывает по эффективности у полносвязной, так как она специально разработана для работы с изображениями.

В целом, написание нейронных сетей, это довольно творческий процесс и подход к ее созданию у каждого программиста может разным, опираясь на его знания и опыт, при согласованности с поставленными задачами.

## Краткое описание работы в группе из 4х человек

### Критерии тренировки первой модели:

|                    | **Участник 1**                                         | **Участник 2**                                               | **Участник 3**                    | **Участник 4**                   |
| ------------------ | ------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------- | -------------------------------- |
|                    | написание отчёта, по предоставленным данным участников | обучение нейросети по заданным параметрам. Отправка скриншотов и составление своей статистики участнику 1 | см. функции участника 2           | см. функции участника 2          |
| **epochs**         | -                                                      | 25                                                           | 50                                | 100                              |
| **bach_size**      |                                                        | 1024                                                         | 1024                              | 1024                             |
| **время обучения** | -                                                      | ~1 час (CPU)<br />~2 мин (GPU)                               | ~2,5 часа (CPU)<br />~4 мин (GPU) | ~4 часов (CPU)<br />~6 мин (GPU) |

*Таблица 1. Данные для тренировки первой модели*

![img](https://lh7-us.googleusercontent.com/is7z0eG2DZuI8a06WTJ57DhuVtOTzYCOlQn2TPBN4ti547TcwalWt-nrvgdlP4fVhlKNFop2tSsJjKs819egXSEqTQuIWqP80pAaFq8J8_3VviahVoY595b8MIdfRTnLy9-PQPhlBfs2gkbnZ7C_qQ)

*Рисунок 20. Гистограмма распознания первой моделью*

Стоит учитывать, что модель лучше распознает цифры, написанные в центре холста. Для достижения хорошего распознавания написанных цифр настоятельно не рекомендуется рисовать цифры на краях холста, 

### Критерии тренировки второй модели:

|                      | **Участник 1**                                         | **Участник 2**                                               | **Участник 3**          | **Участник 4**          |
| -------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ----------------------- | ----------------------- |
|                      | написание отчёта, по предоставленным данным участников | обучение нейросети по заданным параметрам. Отправка скриншотов и составление своей статистики участнику 1 | см. функции участника 2 | см. функции участника 2 |
| **epochs**           | -                                                      | 1500                                                         | 2500                    | 4900                    |
| **validation_split** | -                                                      | 0,1                                                          | 0,2                     | 0,3                     |
| **время обучения**   | -                                                      | ~40 мин.                                                     | ~1,5 ч.                 | ~4,5 ч.                 |

*Таблица 2. Данные для обучения второй модели*

### Описание работы участника 1:

Участнику 1 необходимо отразить в документе все скриншоты, сделанные участниками 2-4, а также составить график при помощи встроенных в Word инструментов, который будет отражать статистику распознаваний/не распознаваний чисел.

**Пример графика:**

График количества распознанных символов исходя из количества проверок распознавания чисел (по оси x – числа, которые подставляем в программу, по оси y – количество верно угаданных ответов, графики строятся по количеству проходок обучения). Вы можете предложить свой тип графика. 

![img](https://lh7-us.googleusercontent.com/BuLipb_ZRTUqDv3qUP70p7tKujaBzRwXZWYmYVelHrxvPdvF9lPWMT5tvcfp9OAA6ZCt1Ae7R8jb-KJbVxXN9uFCTMwAiWdyRa24-gXeL-LMyX7yUMDpmVDYNjpRhpe3qWHZrN0tvDNcR50AivGWew)

*Рисунок 21. График сравнения точности распознавания при разных обучениях*

### Описание работы участников 2-4:

**Задание**: разделить ресурсы, для создания разной точности определения чисел изменяя **epochs** и **validation**_**split**.

**Примеры распределения:**

```python
model.fit(x_train,y_train_cat,batch_size=100,epochs=1500,validation_split=0.1)
```

```python
model.fit(x_train,y_train_cat,batch_size=100,epochs=2500,validation_split=0.2)
```

```python
model.fit(x_train,y_train_cat,batch_size=100,epochs=4900,validation_split=0.3)
```



### Описание тестов нейросети, которые проводят участники 2-4:

После того, как мы обучили нейросеть, для определения точности будем использовать набор тестов: введем следующий набор чисел: 1 3 5 7 2(x4) – эти числа чаще всего путаются в данной нейросети. Вводить их следует блоками (последовательно 1, 3, 5, 7, 2, повторить блок). 

Для каждого из тестов следует приложить скриншот (20 скриншотов), а также общую статистику (1 -распозналась 2 раза, 3 – распозналась 1 раз, и т.д.) распознавания/не распознавания чисел.

### Примеры скриншотов:

![img](https://lh7-us.googleusercontent.com/UksZHkG75qgw1s3ZEJY5xr5BzDFKO7VqQvZbmS7mxOK3zcxMItbyZ1sb5C2CUkPq-jV0Cg65YxjmSobomrB7HJMCSeUy_v_XzggE9dKTXFyV_8w9AgYQL4mRZ0igHJJMH7Sdfuq1Zjoq)

![img](https://lh7-us.googleusercontent.com/T4c1RlgT2qN7I1tiYJnW474eN879M9HbXKlEpxvaZG2oGeUBWQHWv0DiVhYB3MKjmN6Qg0TWqGqXGlddn7RSeGCtyjO1NW6_bmfXCLIV2WbpXPhRqGfkhd-fP5TCilW88Ryu9LAmFwSN)
